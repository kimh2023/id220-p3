{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# from datetime import datetime, timedelta\n",
    "# from collections import defaultdict\n",
    "\n",
    "# api_key = 'mzrsaV5E9ZwVPQ2biOQGyYansI7Ukh5p'\n",
    "# api_key = 'CGeuqVOhGnPEhw8fZaxDDpSXMklkLVJo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_json(json_data):\n",
    "#     print(json.dumps(json_data, indent=2))\n",
    "\n",
    "# def write_jsonl_file(data, filename):\n",
    "#     # Write data to a JSONL file\n",
    "#     with open(filename, 'a', encoding='utf-8') as file:\n",
    "#         json.dump(data, file, ensure_ascii=False)\n",
    "#         file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_response(url) :\n",
    "#     response = requests.get(url)\n",
    "#     return response.json()\n",
    "\n",
    "# def generate_date_range(start_date, end_date):\n",
    "#     # Generate a date range between start_date and end_date\n",
    "#     current_date = start_date\n",
    "#     while current_date <= end_date:\n",
    "#         yield current_date\n",
    "#         current_date += timedelta(weeks=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_filename = 'all_lists.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     url = f'https://api.nytimes.com/svc/books/v3/lists/names.json?api-key={api_key}' # all lists\n",
    "#     response = return_response(url)\n",
    "\n",
    "#     json.dump(response, file, indent=4)\n",
    "#     print(f'All lists saved to {output_filename}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_str = '2011-02-13'\n",
    "# start_date_str = '2017-01-01' # API breakpoint\n",
    "# end_date_str = '2023-12-10'\n",
    "\n",
    "# start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "# end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "\n",
    "# all_responses = {}\n",
    "# failed_week = []\n",
    "\n",
    "# output_filename = 'all_weeks_2.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     for current_date in generate_date_range(start_date, end_date):\n",
    "#         time.sleep(12) #\n",
    "#         week = current_date.strftime('%Y-%m-%d')\n",
    "#         url = f'https://api.nytimes.com/svc/books/v3/lists/{week}/combined-print-and-e-book-fiction.json?api-key={api_key}'\n",
    "#         response = return_response(url)\n",
    "\n",
    "#         if ('status' in response and response['status']=='OK'):\n",
    "#             book = response['results']['books'][0]\n",
    "#             book = {\n",
    "#                 'date': response['results']['published_date'],\n",
    "#                 'rank': book['rank'],\n",
    "#                 'title': book['title'],\n",
    "#                 'author': book['author'],\n",
    "#                 'primary_isbn10': book['primary_isbn10'],\n",
    "#                 'dagger': book['dagger'],\n",
    "#                 'publisher': book['publisher'],\n",
    "#                 'weeks_on_list': book['weeks_on_list']\n",
    "#             }\n",
    "#             month = book['date'].split(\"-\")[0]+'-'+book['date'].split(\"-\")[1]\n",
    "#             if month in all_responses:\n",
    "#                 all_responses[month].append(book)\n",
    "#             else:\n",
    "#                 all_responses[month] = [book]\n",
    "\n",
    "#             print(f'Response for week {week} added to the list.')\n",
    "\n",
    "#         else:\n",
    "#             print(week)\n",
    "#             failed_week.append(week)\n",
    "\n",
    "#     json.dump(all_responses, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'all_months.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book \n",
    "            \n",
    "#     json.dump(all_responses_month, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from collections import Counter\n",
    "# import json\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'p3js/all_months.csv'\n",
    "\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     header = ['rank', 'title', 'author','primary_isbn10','dagger','publisher','weeks_on_list']\n",
    "#     csv_writer.writerow(['month']+header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  # Add other column values as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "\n",
    "# # Paths to your files\n",
    "# json_input_filename = 'all_weeks.json'\n",
    "# csv_input_filename = 'all_months.csv'\n",
    "# output_filename = 'all_weeks_updated.json'\n",
    "\n",
    "# # Load the original JSON data\n",
    "# with open(json_input_filename, 'r', encoding='utf-8') as json_file:\n",
    "#     original_data = json.load(json_file)\n",
    "\n",
    "# # Create a dictionary to store additional details based on book title\n",
    "# book_details = {}\n",
    "\n",
    "# # Read the detailed information from the CSV file\n",
    "# with open(csv_input_filename, 'r', encoding='utf-8') as csv_file:\n",
    "#     csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "#     for row in csv_reader:\n",
    "#         title = row['title']\n",
    "#         genre = row['genre']\n",
    "#         pages = row['pages']\n",
    "\n",
    "#         # Store genre and page information based on book title\n",
    "#         book_details[title] = {'genre': genre, 'pages': pages}\n",
    "\n",
    "# # Update the original data with additional details\n",
    "# for month, books in original_data.items():\n",
    "#     for book in books:\n",
    "#         title = book['title']\n",
    "\n",
    "#         # Check if additional details are available for this book title\n",
    "#         if title in book_details:\n",
    "#             book['genre'] = book_details[title]['genre']\n",
    "#             book['pages'] = book_details[title]['pages']\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "#     json.dump(original_data, json_output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks_updated.json'\n",
    "# output_filename = 'all_months_again.csv'\n",
    "\n",
    "# # Open the output CSV file for writing\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "#     # Specify the header for the CSV file\n",
    "#     header = ['rank', 'title', 'author', 'primary_isbn10', 'dagger', 'publisher', 'weeks_on_list','genre','pages']\n",
    "    \n",
    "#     csv_writer.writerow(['month'] + header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "#         title_counts = Counter(book['title'] for book in all_books)\n",
    "#         author_counts = Counter(book['author'] for book in all_books)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "#             book_list.reverse() # use highest week count\n",
    "            \n",
    "#             most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "#             if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "#                 max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "#                 most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "#                 if len(most_common_books) == 1:\n",
    "#                     most_common_book = most_common_books[0]\n",
    "#                 else:\n",
    "#                     most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "#                 all_responses_month[month] = most_common_book\n",
    "#             print(most_common_book['title'])\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'all_months.json'\n",
    "\n",
    "# with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#     data = json.load(read_file)\n",
    "\n",
    "#     all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "#     title_counts = Counter(book['title'] for book in all_books)\n",
    "#     author_counts = Counter(book['author'] for book in all_books)\n",
    "    \n",
    "#     print(author_counts)\n",
    "\n",
    "# #     for month in data.keys():\n",
    "# #         book_list = data[month]\n",
    "# #         book_list.reverse() # use highest week count\n",
    "        \n",
    "# #         most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "# #         if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "# #             max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "# #             most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "# #             if len(most_common_books) == 1:\n",
    "# #                 most_common_book = most_common_books[0]\n",
    "# #             else:\n",
    "# #                 most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "# #             all_responses_month[month] = most_common_book\n",
    "# #         print(most_common_book['title'])\n",
    "\n",
    "# #         all_responses_month[month] = most_common_book\n",
    "\n",
    "# # with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "# #     json.dump(all_responses_month, json_output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTHOR INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# author_input_filename = 'author_info.json'\n",
    "# input_filename = 'all_months.json'\n",
    "# output_filename = 'all_months_author.json'\n",
    "\n",
    "# with open(author_input_filename, 'r', encoding='utf-8') as author_read_file:\n",
    "#     author_data = json.load(author_read_file)\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book = data[month]\n",
    "#             author_names = book['author'].split(' and ')\n",
    "#             book['author'] = author_names\n",
    "\n",
    "#             author_info = {}\n",
    "\n",
    "#             for author in author_names:\n",
    "#                 author_info[author] = {}\n",
    "\n",
    "#                 for key in author_data['James Patterson']:\n",
    "#                     if key=='books':\n",
    "#                         continue\n",
    "#                     if not author in author_data:\n",
    "#                         print(book['author'])\n",
    "#                     author_info[author][key] = author_data[author][key]\n",
    "\n",
    "#             book['author'] = author_info\n",
    "\n",
    "#             all_responses_month[month] = book\n",
    "\n",
    "\n",
    "\n",
    "# with open(output_filename, 'w', encoding='utf-8') as json_file:\n",
    "#     json.dump(all_responses_month, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add all books from all_weeks to author_info\n",
    "# import json\n",
    "\n",
    "# existing_json_filename = 'save-author_info.json'\n",
    "# new_json_filename = 'all_weeks.json'\n",
    "# output_filename = 'author_info.json'\n",
    "\n",
    "# # Load the existing JSON data\n",
    "# with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "#     existing_data = json.load(existing_file)\n",
    "\n",
    "# # Load the new JSON data\n",
    "# with open(new_json_filename, 'r', encoding='utf-8') as new_file:\n",
    "#     new_data = json.load(new_file)\n",
    "\n",
    "# # Update the existing JSON data with additional book information\n",
    "# for month, books in new_data.items():\n",
    "#     for book_entry in books:\n",
    "#         author_names = book_entry['author'].split(' and ')\n",
    "#         for author_name in author_names:\n",
    "#             # Check if the author exists in the existing data\n",
    "#             if author_name in existing_data:\n",
    "#                 book_title = book_entry['title']\n",
    "#                 # Add the book to the author's list of books if it's not already present\n",
    "#                 if book_title not in existing_data[author_name]['books']:\n",
    "#                     existing_data[author_name]['books'].append(book_title)\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "#     json.dump(existing_data, output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# existing_json_filename = 'save-author_info.json'\n",
    "# output_filename = 'author_info.json'\n",
    "\n",
    "# # Load the existing JSON data\n",
    "# with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "#     existing_data = json.load(existing_file)\n",
    "\n",
    "# # Prompt the user to input the date of birth for each author\n",
    "# for author_name, author_info in existing_data.items():\n",
    "#     # BIRTHHHH\n",
    "#     # if 'birth_year' not in author_info:\n",
    "#     #     # Prompt the user for input\n",
    "#     #     date_of_birth = input(f\"Enter the year of birth for {author_name}: \")\n",
    "        \n",
    "#     #     # Update the existing data with the date of birth\n",
    "#     #     existing_data[author_name]['birth_year'] = date_of_birth\n",
    "\n",
    "#     # BOOK COUNT\n",
    "#     existing_data[author_name]['multiple_books'] = len(existing_data[author_name]['books']) > 1\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "#     json.dump(existing_data, output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import json\n",
    "\n",
    "# json_filename = 'all_months_author.json'\n",
    "# csv_filename = 'all_months.csv'\n",
    "\n",
    "# # Load the JSON data\n",
    "# with open(json_filename, 'r', encoding='utf-8') as json_file:\n",
    "#     data = json.load(json_file)\n",
    "\n",
    "# # Open the CSV file for writing\n",
    "# with open(csv_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "#     # Write the header to the CSV file\n",
    "#     header = list(data['2011-02'].keys())\n",
    "#     header.remove('author')\n",
    "#     author_header = list(data['2011-02']['author']['James Patterson'].keys())\n",
    "#     csv_writer.writerow(header+['author']+author_header)\n",
    "    \n",
    "#     # Iterate through each month in the JSON data\n",
    "#     for month, book_data in data.items():\n",
    "#         for author, author_data in book_data['author'].items():\n",
    "#             book_data['date'] = month\n",
    "#             data = [book_data[key] for key in header] + [author] + [author_data[key] for key in author_header]\n",
    "\n",
    "#             csv_writer.writerow(data)\n",
    "\n",
    "# print(f\"CSV file saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGAIN FOR AUTHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "all_responses_author = {}\n",
    "\n",
    "input_filename = 'all_weeks.json'\n",
    "output_filename = 'all_authors.json'\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "    all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "    title_counts = Counter(book['title'] for book in all_books)\n",
    "    author_counts = Counter(author.strip() for book in all_books for author in book['author'].split(' and '))\n",
    "\n",
    "    popular_authors = {author:count for author, count in author_counts.items() if count > 5}\n",
    "    \n",
    "    print(len(popular_authors))\n",
    "\n",
    "    for month, books in data.items():\n",
    "        for book_entry in books:\n",
    "            author_names = book_entry['author'].split(' and ')\n",
    "            for author_name in author_names:\n",
    "                # Check if the author exists in the existing data\n",
    "                if author_name in popular_authors:\n",
    "                    if author_name not in all_responses_author:\n",
    "                        all_responses_author[author_name] = {}\n",
    "                        all_responses_author[author_name]['books']=[]\n",
    "\n",
    "                    if any(entry['title'] == book_entry['title'] for entry in all_responses_author[author_name]['books']):\n",
    "                        for entry in all_responses_author[author_name]['books']:\n",
    "                            if entry['title'] == book_entry['title']:\n",
    "                                entry['book_count'] += 1\n",
    "                                entry['dates'].append(book_entry['date'])\n",
    "                                entry['weeks_on_list'] = book_entry['weeks_on_list']\n",
    "                    else: \n",
    "                        copied = copy.deepcopy(book_entry)\n",
    "                        copied['book_count'] = 1\n",
    "                        copied['dates'] = [book_entry['date']]\n",
    "                        del copied['date']\n",
    "                        del copied['rank']\n",
    "                        del copied['dagger']\n",
    "            \n",
    "                        all_responses_author[author_name]['count'] = popular_authors[author_name]\n",
    "                        all_responses_author[author_name]['books'].append(copied)\n",
    "                    \n",
    "all_responses_author = dict(sorted(all_responses_author.items(),key=lambda x: x[1]['count'], reverse=True))\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "    json.dump(all_responses_author, json_output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grisham practiced law for about a decade and won election as a Democrat to the Mississippi House of Representatives, serving from 1983 to 1990.[6][12] He challenged the incumbent after becoming embarrassed by Mississippi's national reputation and inspired by the passage of the Education Reform Act of 1982.[13] Grisham represented the 7th District, which included DeSoto County, Mississippi.[14] By his second term in the state legislature, he was the vice-chairman of the Apportionment and Elections Committee and a member of several other committees.[1] He supported Representative Ed Perry's unsuccessful bid for the House speakership in 1987. With a different speaker elected at the beginning of the 1988 legislative session, Grisham was out of favor with the new legislative leaders and assigned to more minor committee roles. Not as busy with political affairs, he devoted more time to his novel, The Firm. Grisham later reflected that if Perry had become speaker he might have been given more committee responsibilities and thus unable to write.[15]\n",
      "\n",
      "John Grisham did not work in the publishing industry.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_author_career(author_name):\n",
    "    # Search for the author's Wikipedia page\n",
    "    search_url = f\"https://en.wikipedia.org/wiki/{author_name.replace(' ', '_')}\"\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract relevant information about the author's career\n",
    "        career_section = soup.find('span', {'id': 'Career'})\n",
    "        if career_section:\n",
    "            # Assuming the information is in the next paragraph after the 'Career' section\n",
    "            career_paragraph = career_section.find_next('p')\n",
    "            career_text = career_paragraph.get_text()\n",
    "            print(career_text)\n",
    "\n",
    "            # Check if the author worked in the publishing industry\n",
    "            worked_in_publishing = \"publish\" in career_text.lower()\n",
    "            \n",
    "            return worked_in_publishing\n",
    "\n",
    "    # Return None if no information is found\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "# author_name = \"John Grisham\"\n",
    "# worked_in_publishing = get_author_career(author_name)\n",
    "\n",
    "# if worked_in_publishing is not None:\n",
    "#     print(f\"{author_name} {'did' if worked_in_publishing else 'did not'} work in the publishing industry.\")\n",
    "# else:\n",
    "#     print(f\"Unable to retrieve information about {author_name}'s career.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/hyuna/Desktop/id220-p3/main.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hyuna/Desktop/id220-p3/main.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         data[author_name][\u001b[39m'\u001b[39m\u001b[39mcareer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m author_info[\u001b[39m'\u001b[39m\u001b[39mcareer\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hyuna/Desktop/id220-p3/main.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m book \u001b[39min\u001b[39;00m data[author_name][\u001b[39m\"\u001b[39m\u001b[39mbooks\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hyuna/Desktop/id220-p3/main.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             book[\u001b[39m'\u001b[39m\u001b[39mpages\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m((myBook \u001b[39mfor\u001b[39;49;00m myBook \u001b[39min\u001b[39;49;00m data[author_name][\u001b[39m\"\u001b[39;49m\u001b[39mbooks\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39mif\u001b[39;49;00m myBook[\u001b[39m\"\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m book[\u001b[39m\"\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m\"\u001b[39;49m]), \u001b[39mNone\u001b[39;49;00m)[\u001b[39m'\u001b[39;49m\u001b[39mpages\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hyuna/Desktop/id220-p3/main.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m author_name, author_info \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hyuna/Desktop/id220-p3/main.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     all_book_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(author_info[\u001b[39m'\u001b[39m\u001b[39mbooks\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pages'"
     ]
    }
   ],
   "source": [
    "input_filename = 'all_authors.json'\n",
    "existing_json_filename = 'author_info.json'\n",
    "# output_filename = 'all_authors_update.json'\n",
    "output_filename = 'tmp5/all_authors.json'\n",
    "\n",
    "all_book_count = 0\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "    existing_data = json.load(existing_file)\n",
    "\n",
    "# Prompt the user to input the date of birth for each author\n",
    "for author_name, author_info in existing_data.items():\n",
    "    if author_name in data:\n",
    "        data[author_name]['gender'] = author_info['gender']\n",
    "        data[author_name]['birth_year'] = int(author_info['birth_year'])\n",
    "        data[author_name]['university'] = author_info['university']\n",
    "        data[author_name]['major'] = author_info['major']\n",
    "        data[author_name]['career'] = author_info['career']\n",
    "        for book in data[author_name][\"books\"]:\n",
    "            book['pages'] = next((myBook for myBook in data[author_name][\"books\"] if myBook[\"title\"] == book[\"title\"]), None)['pages']\n",
    "\n",
    "for author_name, author_info in data.items():\n",
    "    all_book_count += len(author_info['books'])\n",
    "    if 'gender' not in author_info:\n",
    "        gender = input(f\"input {author_name}'s gender\")\n",
    "        data[author_name]['gender'] = gender\n",
    "    if 'birth_year' not in author_info:\n",
    "        birth_year = input(f\"input {author_name}'s birth year\")\n",
    "        data[author_name]['birth_year'] = birth_year\n",
    "    if 'university' not in author_info:\n",
    "        university = input(f\"input {author_name}'s university\")\n",
    "        data[author_name]['university'] = university\n",
    "    if 'major' not in author_info:\n",
    "        major = input(f\"input {author_name}'s major\")\n",
    "        data[author_name]['major'] = major\n",
    "    for book in data[author_name][\"books\"]:\n",
    "        if \"genre\" not in book:\n",
    "            genre = input(f\"input {book['title']} by {author_name} genre\")\n",
    "            book[\"genre\"] = genre\n",
    "            break\n",
    "        if 'pages' not in book:\n",
    "            pages = input(f\"input {book['title']}'s page count\")\n",
    "            book[\"pages\"] = pages\n",
    "\n",
    "    # worked_in_publishing = get_author_career(author_name)\n",
    "    # if worked_in_publishing is not None:\n",
    "    #     if worked_in_publishing:\n",
    "    #         worked_in_publishing = input(f\"input 1 if {author_name} really worked in publishing\")\n",
    "    # else:\n",
    "    #     worked_in_publishing = input(f\"no info: input 1 if {author_name} really worked in publishing\")\n",
    "    # data[author_name]['worked_in_publishing'] = worked_in_publishing\n",
    "    \n",
    "    # print(data[author_name]['university'])\n",
    "    # university = input(f\"type something to change {author_name}'s university\")\n",
    "    # if university:\n",
    "    #     print(\"HI\")\n",
    "    #     data[author_name]['university'] = university\n",
    "\n",
    "\n",
    "# Save the updated data to a new JSON file\n",
    "with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(data, output_file, indent=2)\n",
    "\n",
    "# majors = [major for author_info in data.values() for major in author_info.get('major')]\n",
    "majors = [author_info.get('major') for author_info in data.values() ]\n",
    "major_counter = Counter(majors)\n",
    "\n",
    "print(major_counter)\n",
    "sum = 0\n",
    "for major, count in major_counter.items():\n",
    "    sum += count\n",
    "print(sum)\n",
    "print(\"BOOKS\",all_book_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
