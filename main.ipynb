{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# from datetime import datetime, timedelta\n",
    "# from collections import defaultdict\n",
    "\n",
    "# api_key = 'mzrsaV5E9ZwVPQ2biOQGyYansI7Ukh5p'\n",
    "# api_key = 'CGeuqVOhGnPEhw8fZaxDDpSXMklkLVJo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_json(json_data):\n",
    "#     print(json.dumps(json_data, indent=2))\n",
    "\n",
    "# def write_jsonl_file(data, filename):\n",
    "#     # Write data to a JSONL file\n",
    "#     with open(filename, 'a', encoding='utf-8') as file:\n",
    "#         json.dump(data, file, ensure_ascii=False)\n",
    "#         file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_response(url) :\n",
    "#     response = requests.get(url)\n",
    "#     return response.json()\n",
    "\n",
    "# def generate_date_range(start_date, end_date):\n",
    "#     # Generate a date range between start_date and end_date\n",
    "#     current_date = start_date\n",
    "#     while current_date <= end_date:\n",
    "#         yield current_date\n",
    "#         current_date += timedelta(weeks=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_filename = 'all_lists.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     url = f'https://api.nytimes.com/svc/books/v3/lists/names.json?api-key={api_key}' # all lists\n",
    "#     response = return_response(url)\n",
    "\n",
    "#     json.dump(response, file, indent=4)\n",
    "#     print(f'All lists saved to {output_filename}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_str = '2011-02-13'\n",
    "# start_date_str = '2017-01-01' # API breakpoint\n",
    "# end_date_str = '2023-12-10'\n",
    "\n",
    "# start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "# end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "\n",
    "# all_responses = {}\n",
    "# failed_week = []\n",
    "\n",
    "# output_filename = 'all_weeks_2.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     for current_date in generate_date_range(start_date, end_date):\n",
    "#         time.sleep(12) #\n",
    "#         week = current_date.strftime('%Y-%m-%d')\n",
    "#         url = f'https://api.nytimes.com/svc/books/v3/lists/{week}/combined-print-and-e-book-fiction.json?api-key={api_key}'\n",
    "#         response = return_response(url)\n",
    "\n",
    "#         if ('status' in response and response['status']=='OK'):\n",
    "#             book = response['results']['books'][0]\n",
    "#             book = {\n",
    "#                 'date': response['results']['published_date'],\n",
    "#                 'rank': book['rank'],\n",
    "#                 'title': book['title'],\n",
    "#                 'author': book['author'],\n",
    "#                 'primary_isbn10': book['primary_isbn10'],\n",
    "#                 'dagger': book['dagger'],\n",
    "#                 'publisher': book['publisher'],\n",
    "#                 'weeks_on_list': book['weeks_on_list']\n",
    "#             }\n",
    "#             month = book['date'].split(\"-\")[0]+'-'+book['date'].split(\"-\")[1]\n",
    "#             if month in all_responses:\n",
    "#                 all_responses[month].append(book)\n",
    "#             else:\n",
    "#                 all_responses[month] = [book]\n",
    "\n",
    "#             print(f'Response for week {week} added to the list.')\n",
    "\n",
    "#         else:\n",
    "#             print(week)\n",
    "#             failed_week.append(week)\n",
    "\n",
    "#     json.dump(all_responses, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'all_months.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book \n",
    "            \n",
    "#     json.dump(all_responses_month, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from collections import Counter\n",
    "# import json\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'p3js/all_months.csv'\n",
    "\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     header = ['rank', 'title', 'author','primary_isbn10','dagger','publisher','weeks_on_list']\n",
    "#     csv_writer.writerow(['month']+header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  # Add other column values as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to all_weeks_updated.json\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# import json\n",
    "\n",
    "# # Paths to your files\n",
    "# json_input_filename = 'all_weeks.json'\n",
    "# csv_input_filename = 'all_months.csv'\n",
    "# output_filename = 'all_weeks_updated.json'\n",
    "\n",
    "# # Load the original JSON data\n",
    "# with open(json_input_filename, 'r', encoding='utf-8') as json_file:\n",
    "#     original_data = json.load(json_file)\n",
    "\n",
    "# # Create a dictionary to store additional details based on book title\n",
    "# book_details = {}\n",
    "\n",
    "# # Read the detailed information from the CSV file\n",
    "# with open(csv_input_filename, 'r', encoding='utf-8') as csv_file:\n",
    "#     csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "#     for row in csv_reader:\n",
    "#         title = row['title']\n",
    "#         genre = row['genre']\n",
    "#         pages = row['pages']\n",
    "\n",
    "#         # Store genre and page information based on book title\n",
    "#         book_details[title] = {'genre': genre, 'pages': pages}\n",
    "\n",
    "# # Update the original data with additional details\n",
    "# for month, books in original_data.items():\n",
    "#     for book in books:\n",
    "#         title = book['title']\n",
    "\n",
    "#         # Check if additional details are available for this book title\n",
    "#         if title in book_details:\n",
    "#             book['genre'] = book_details[title]['genre']\n",
    "#             book['pages'] = book_details[title]['pages']\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "#     json.dump(original_data, json_output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICK TOCK\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "11/22/63\n",
      "THE DROP\n",
      "THE HELP\n",
      "EXTREMELY LOUD AND INCREDIBLY CLOSE\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "REFLECTED IN YOU\n",
      "THE RACKETEER\n",
      "GONE GIRL\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "THE BET\n",
      "WHISKEY BEACH\n",
      "INFERNO\n",
      "INFERNO\n",
      "THE CUCKOO'S CALLING\n",
      "THE CUCKOO'S CALLING\n",
      "STORM FRONT\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "THE GOLDFINCH\n",
      "CONCEALED IN DEATH\n",
      "SHADOW SPELL\n",
      "UNLUCKY 13\n",
      "UNLUCKY 13\n",
      "INVISIBLE\n",
      "FIFTY SHADES OF GREY\n",
      "OUTLANDER\n",
      "GONE GIRL\n",
      "GONE GIRL\n",
      "ALL THE LIGHT WE CANNOT SEE\n",
      "GONE GIRL\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "GREY\n",
      "GO SET A WATCHMAN\n",
      "MAKE ME\n",
      "THE MARTIAN\n",
      "ROGUE LAWYER\n",
      "ROGUE LAWYER\n",
      "THE GIRL ON THE TRAIN\n",
      "BROTHERHOOD IN DEATH\n",
      "ME BEFORE YOU\n",
      "FOOL ME ONCE\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "A DOG'S PURPOSE\n",
      "THE SHACK\n",
      "THE SHACK\n",
      "INTO THE WATER\n",
      "CAMINO ISLAND\n",
      "CAMINO ISLAND\n",
      "THE LATE SHOW\n",
      "SECRETS IN DEATH\n",
      "ORIGIN\n",
      "ORIGIN\n",
      "THE ROOSTER BAR\n",
      "ORIGIN\n",
      "THE GREAT ALONE\n",
      "THE GREAT ALONE\n",
      "READY PLAYER ONE\n",
      "THE 17TH SUSPECT\n",
      "THE PRESIDENT IS MISSING\n",
      "THE PRESIDENT IS MISSING\n",
      "ORIGIN\n",
      "CRAZY RICH ASIANS\n",
      "HOLY GHOST\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "THE INSTITUTE\n",
      "BLUE MOON\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "AMERICAN DIRT\n",
      "LITTLE FIRES EVERYWHERE\n",
      "CAMINO WINDS\n",
      "THE VANISHING HALF\n",
      "THE VANISHING HALF\n",
      "WHERE THE CRAWDADS SING\n",
      "SHADOWS IN DEATH\n",
      "THE RETURN\n",
      "A TIME FOR MERCY\n",
      "READY PLAYER TWO\n",
      "THE DUKE AND I\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "SOOLEY\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "FORGOTTEN IN DEATH\n",
      "APPLES NEVER FALL\n",
      "THE JUDGE'S LIST\n",
      "CALL US WHAT WE CARRY\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "HOUSE OF SKY AND BREATH\n",
      "WHERE THE CRAWDADS SING\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "HAPPY PLACE\n",
      "HAPPY PLACE\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "IRON FLAME\n",
      "IRON FLAME\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks_updated.json'\n",
    "# output_filename = 'all_months_again.csv'\n",
    "\n",
    "# # Open the output CSV file for writing\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "#     # Specify the header for the CSV file\n",
    "#     header = ['rank', 'title', 'author', 'primary_isbn10', 'dagger', 'publisher', 'weeks_on_list','genre','pages']\n",
    "    \n",
    "#     csv_writer.writerow(['month'] + header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "#         title_counts = Counter(book['title'] for book in all_books)\n",
    "#         author_counts = Counter(book['author'] for book in all_books)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "#             book_list.reverse() # use highest week count\n",
    "            \n",
    "#             most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "#             if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "#                 max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "#                 most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "#                 if len(most_common_books) == 1:\n",
    "#                     most_common_book = most_common_books[0]\n",
    "#                 else:\n",
    "#                     most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "#                 all_responses_month[month] = most_common_book\n",
    "#             print(most_common_book['title'])\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICK TOCK\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "11/22/63\n",
      "THE DROP\n",
      "THE HELP\n",
      "EXTREMELY LOUD AND INCREDIBLY CLOSE\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "REFLECTED IN YOU\n",
      "THE RACKETEER\n",
      "GONE GIRL\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "THE BET\n",
      "WHISKEY BEACH\n",
      "INFERNO\n",
      "INFERNO\n",
      "THE CUCKOO'S CALLING\n",
      "THE CUCKOO'S CALLING\n",
      "STORM FRONT\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "THE GOLDFINCH\n",
      "CONCEALED IN DEATH\n",
      "SHADOW SPELL\n",
      "UNLUCKY 13\n",
      "UNLUCKY 13\n",
      "INVISIBLE\n",
      "FIFTY SHADES OF GREY\n",
      "OUTLANDER\n",
      "GONE GIRL\n",
      "GONE GIRL\n",
      "ALL THE LIGHT WE CANNOT SEE\n",
      "GONE GIRL\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "GREY\n",
      "GO SET A WATCHMAN\n",
      "MAKE ME\n",
      "THE MARTIAN\n",
      "ROGUE LAWYER\n",
      "ROGUE LAWYER\n",
      "THE GIRL ON THE TRAIN\n",
      "BROTHERHOOD IN DEATH\n",
      "ME BEFORE YOU\n",
      "FOOL ME ONCE\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "A DOG'S PURPOSE\n",
      "THE SHACK\n",
      "THE SHACK\n",
      "INTO THE WATER\n",
      "CAMINO ISLAND\n",
      "CAMINO ISLAND\n",
      "THE LATE SHOW\n",
      "SECRETS IN DEATH\n",
      "ORIGIN\n",
      "ORIGIN\n",
      "THE ROOSTER BAR\n",
      "ORIGIN\n",
      "THE GREAT ALONE\n",
      "THE GREAT ALONE\n",
      "READY PLAYER ONE\n",
      "THE 17TH SUSPECT\n",
      "THE PRESIDENT IS MISSING\n",
      "THE PRESIDENT IS MISSING\n",
      "ORIGIN\n",
      "CRAZY RICH ASIANS\n",
      "HOLY GHOST\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "THE INSTITUTE\n",
      "BLUE MOON\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "AMERICAN DIRT\n",
      "LITTLE FIRES EVERYWHERE\n",
      "CAMINO WINDS\n",
      "THE VANISHING HALF\n",
      "THE VANISHING HALF\n",
      "WHERE THE CRAWDADS SING\n",
      "SHADOWS IN DEATH\n",
      "THE RETURN\n",
      "A TIME FOR MERCY\n",
      "READY PLAYER TWO\n",
      "THE DUKE AND I\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "SOOLEY\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "FORGOTTEN IN DEATH\n",
      "APPLES NEVER FALL\n",
      "THE JUDGE'S LIST\n",
      "CALL US WHAT WE CARRY\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "HOUSE OF SKY AND BREATH\n",
      "WHERE THE CRAWDADS SING\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "HAPPY PLACE\n",
      "HAPPY PLACE\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "IRON FLAME\n",
      "IRON FLAME\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "all_responses_month = {}\n",
    "\n",
    "input_filename = 'all_weeks_updated.json'\n",
    "output_filename = 'all_months.json'\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "    all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "    title_counts = Counter(book['title'] for book in all_books)\n",
    "    author_counts = Counter(book['author'] for book in all_books)\n",
    "\n",
    "    for month in data.keys():\n",
    "        book_list = data[month]\n",
    "        book_list.reverse() # use highest week count\n",
    "        \n",
    "        most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "        if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "            max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "            most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "            if len(most_common_books) == 1:\n",
    "                most_common_book = most_common_books[0]\n",
    "            else:\n",
    "                most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "            all_responses_month[month] = most_common_book\n",
    "        print(most_common_book['title'])\n",
    "\n",
    "        all_responses_month[month] = most_common_book\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "    json.dump(all_responses_month, json_output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTHOR INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "input_filename = 'all_months_author_added.csv'\n",
    "output_filename = 'author_info.json'\n",
    "\n",
    "# Initialize an empty dictionary to store author data\n",
    "author_data = {}\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(input_filename, 'r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    # Iterate through each row in the CSV\n",
    "    for row in csv_reader:\n",
    "        # Extract relevant information from the row\n",
    "        author_names = row['author'].split(' and ')\n",
    "\n",
    "        author_gender = row['author_gender']\n",
    "        book_title = row['title']\n",
    "        \n",
    "        for author_name in author_names:\n",
    "            if author_name not in author_data:\n",
    "                author_data[author_name] = {'gender': author_gender, 'books': []}\n",
    "            \n",
    "            # Add the book to the author's list of books\n",
    "            if book_title not in author_data[author_name]['books']:\n",
    "                author_data[author_name]['books'].append(book_title)\n",
    "\n",
    "# Save the author data to a JSON file\n",
    "with open(output_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(author_data, json_file, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
