{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# from datetime import datetime, timedelta\n",
    "# from collections import defaultdict\n",
    "\n",
    "# api_key = 'mzrsaV5E9ZwVPQ2biOQGyYansI7Ukh5p'\n",
    "# api_key = 'CGeuqVOhGnPEhw8fZaxDDpSXMklkLVJo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_json(json_data):\n",
    "#     print(json.dumps(json_data, indent=2))\n",
    "\n",
    "# def write_jsonl_file(data, filename):\n",
    "#     # Write data to a JSONL file\n",
    "#     with open(filename, 'a', encoding='utf-8') as file:\n",
    "#         json.dump(data, file, ensure_ascii=False)\n",
    "#         file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_response(url) :\n",
    "#     response = requests.get(url)\n",
    "#     return response.json()\n",
    "\n",
    "# def generate_date_range(start_date, end_date):\n",
    "#     # Generate a date range between start_date and end_date\n",
    "#     current_date = start_date\n",
    "#     while current_date <= end_date:\n",
    "#         yield current_date\n",
    "#         current_date += timedelta(weeks=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_filename = 'all_lists.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     url = f'https://api.nytimes.com/svc/books/v3/lists/names.json?api-key={api_key}' # all lists\n",
    "#     response = return_response(url)\n",
    "\n",
    "#     json.dump(response, file, indent=4)\n",
    "#     print(f'All lists saved to {output_filename}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting All Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date_str = '2011-02-13'\n",
    "# start_date_str = '2017-01-01' # API breakpoint\n",
    "# end_date_str = '2023-12-10'\n",
    "\n",
    "# start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "# end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "\n",
    "# all_responses = {}\n",
    "# failed_week = []\n",
    "\n",
    "# output_filename = 'all_weeks_2.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     for current_date in generate_date_range(start_date, end_date):\n",
    "#         time.sleep(12) #\n",
    "#         week = current_date.strftime('%Y-%m-%d')\n",
    "#         url = f'https://api.nytimes.com/svc/books/v3/lists/{week}/combined-print-and-e-book-fiction.json?api-key={api_key}'\n",
    "#         response = return_response(url)\n",
    "\n",
    "#         if ('status' in response and response['status']=='OK'):\n",
    "#             book = response['results']['books'][0]\n",
    "#             book = {\n",
    "#                 'date': response['results']['published_date'],\n",
    "#                 'rank': book['rank'],\n",
    "#                 'title': book['title'],\n",
    "#                 'author': book['author'],\n",
    "#                 'primary_isbn10': book['primary_isbn10'],\n",
    "#                 'dagger': book['dagger'],\n",
    "#                 'publisher': book['publisher'],\n",
    "#                 'weeks_on_list': book['weeks_on_list']\n",
    "#             }\n",
    "#             month = book['date'].split(\"-\")[0]+'-'+book['date'].split(\"-\")[1]\n",
    "#             if month in all_responses:\n",
    "#                 all_responses[month].append(book)\n",
    "#             else:\n",
    "#                 all_responses[month] = [book]\n",
    "\n",
    "#             print(f'Response for week {week} added to the list.')\n",
    "\n",
    "#         else:\n",
    "#             print(week)\n",
    "#             failed_week.append(week)\n",
    "\n",
    "#     json.dump(all_responses, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'all_months.json'\n",
    "# with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book \n",
    "            \n",
    "#     json.dump(all_responses_month, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from collections import Counter\n",
    "# import json\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks.json'\n",
    "# output_filename = 'p3js/all_months.csv'\n",
    "\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     header = ['rank', 'title', 'author','primary_isbn10','dagger','publisher','weeks_on_list']\n",
    "#     csv_writer.writerow(['month']+header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "\n",
    "#             titles = [book['title'] for book in book_list]\n",
    "#             title_counts = Counter(titles)\n",
    "#             most_common_title = title_counts.most_common(1)[0][0]\n",
    "\n",
    "#             most_common_book = next(book for book in book_list if book['title'] == most_common_title)\n",
    "#             all_responses_month[month] = most_common_book\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  # Add other column values as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to all_weeks_updated.json\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# import json\n",
    "\n",
    "# # Paths to your files\n",
    "# json_input_filename = 'all_weeks.json'\n",
    "# csv_input_filename = 'all_months.csv'\n",
    "# output_filename = 'all_weeks_updated.json'\n",
    "\n",
    "# # Load the original JSON data\n",
    "# with open(json_input_filename, 'r', encoding='utf-8') as json_file:\n",
    "#     original_data = json.load(json_file)\n",
    "\n",
    "# # Create a dictionary to store additional details based on book title\n",
    "# book_details = {}\n",
    "\n",
    "# # Read the detailed information from the CSV file\n",
    "# with open(csv_input_filename, 'r', encoding='utf-8') as csv_file:\n",
    "#     csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "#     for row in csv_reader:\n",
    "#         title = row['title']\n",
    "#         genre = row['genre']\n",
    "#         pages = row['pages']\n",
    "\n",
    "#         # Store genre and page information based on book title\n",
    "#         book_details[title] = {'genre': genre, 'pages': pages}\n",
    "\n",
    "# # Update the original data with additional details\n",
    "# for month, books in original_data.items():\n",
    "#     for book in books:\n",
    "#         title = book['title']\n",
    "\n",
    "#         # Check if additional details are available for this book title\n",
    "#         if title in book_details:\n",
    "#             book['genre'] = book_details[title]['genre']\n",
    "#             book['pages'] = book_details[title]['pages']\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "#     json.dump(original_data, json_output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICK TOCK\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "WATER FOR ELEPHANTS\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "THE HELP\n",
      "11/22/63\n",
      "THE DROP\n",
      "THE HELP\n",
      "EXTREMELY LOUD AND INCREDIBLY CLOSE\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "FIFTY SHADES OF GREY\n",
      "REFLECTED IN YOU\n",
      "THE RACKETEER\n",
      "GONE GIRL\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "SAFE HAVEN\n",
      "THE BET\n",
      "WHISKEY BEACH\n",
      "INFERNO\n",
      "INFERNO\n",
      "THE CUCKOO'S CALLING\n",
      "THE CUCKOO'S CALLING\n",
      "STORM FRONT\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "SYCAMORE ROW\n",
      "THE GOLDFINCH\n",
      "CONCEALED IN DEATH\n",
      "SHADOW SPELL\n",
      "UNLUCKY 13\n",
      "UNLUCKY 13\n",
      "INVISIBLE\n",
      "FIFTY SHADES OF GREY\n",
      "OUTLANDER\n",
      "GONE GIRL\n",
      "GONE GIRL\n",
      "ALL THE LIGHT WE CANNOT SEE\n",
      "GONE GIRL\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "GREY\n",
      "GO SET A WATCHMAN\n",
      "MAKE ME\n",
      "THE MARTIAN\n",
      "ROGUE LAWYER\n",
      "ROGUE LAWYER\n",
      "THE GIRL ON THE TRAIN\n",
      "BROTHERHOOD IN DEATH\n",
      "ME BEFORE YOU\n",
      "FOOL ME ONCE\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "ME BEFORE YOU\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE GIRL ON THE TRAIN\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "THE WHISTLER\n",
      "A DOG'S PURPOSE\n",
      "THE SHACK\n",
      "THE SHACK\n",
      "INTO THE WATER\n",
      "CAMINO ISLAND\n",
      "CAMINO ISLAND\n",
      "THE LATE SHOW\n",
      "SECRETS IN DEATH\n",
      "ORIGIN\n",
      "ORIGIN\n",
      "THE ROOSTER BAR\n",
      "ORIGIN\n",
      "THE GREAT ALONE\n",
      "THE GREAT ALONE\n",
      "READY PLAYER ONE\n",
      "THE 17TH SUSPECT\n",
      "THE PRESIDENT IS MISSING\n",
      "THE PRESIDENT IS MISSING\n",
      "ORIGIN\n",
      "CRAZY RICH ASIANS\n",
      "HOLY GHOST\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "THE RECKONING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "THE INSTITUTE\n",
      "BLUE MOON\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "AMERICAN DIRT\n",
      "LITTLE FIRES EVERYWHERE\n",
      "CAMINO WINDS\n",
      "THE VANISHING HALF\n",
      "THE VANISHING HALF\n",
      "WHERE THE CRAWDADS SING\n",
      "SHADOWS IN DEATH\n",
      "THE RETURN\n",
      "A TIME FOR MERCY\n",
      "READY PLAYER TWO\n",
      "THE DUKE AND I\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "THE FOUR WINDS\n",
      "SOOLEY\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "THE LAST THING HE TOLD ME\n",
      "FORGOTTEN IN DEATH\n",
      "APPLES NEVER FALL\n",
      "THE JUDGE'S LIST\n",
      "CALL US WHAT WE CARRY\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "HOUSE OF SKY AND BREATH\n",
      "WHERE THE CRAWDADS SING\n",
      "IT ENDS WITH US\n",
      "IT ENDS WITH US\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "WHERE THE CRAWDADS SING\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "IT STARTS WITH US\n",
      "HAPPY PLACE\n",
      "HAPPY PLACE\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "FOURTH WING\n",
      "IRON FLAME\n",
      "IRON FLAME\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# import json\n",
    "# from collections import Counter\n",
    "\n",
    "# all_responses_month = {}\n",
    "\n",
    "# input_filename = 'all_weeks_updated.json'\n",
    "# output_filename = 'all_months_again.csv'\n",
    "\n",
    "# # Open the output CSV file for writing\n",
    "# with open(output_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "#     # Specify the header for the CSV file\n",
    "#     header = ['rank', 'title', 'author', 'primary_isbn10', 'dagger', 'publisher', 'weeks_on_list','genre','pages']\n",
    "    \n",
    "#     csv_writer.writerow(['month'] + header)  # Add other column headers as needed\n",
    "\n",
    "#     with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "#         data = json.load(read_file)\n",
    "\n",
    "#         all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "#         title_counts = Counter(book['title'] for book in all_books)\n",
    "#         author_counts = Counter(book['author'] for book in all_books)\n",
    "\n",
    "#         for month in data.keys():\n",
    "#             book_list = data[month]\n",
    "#             book_list.reverse() # use highest week count\n",
    "            \n",
    "#             most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "#             if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "#                 max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "#                 most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "#                 if len(most_common_books) == 1:\n",
    "#                     most_common_book = most_common_books[0]\n",
    "#                 else:\n",
    "#                     most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "#                 all_responses_month[month] = most_common_book\n",
    "#             print(most_common_book['title'])\n",
    "\n",
    "#             row = [most_common_book[key] for key in header]\n",
    "#             csv_writer.writerow([month]+row)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'John Grisham': 47, 'Delia Owens': 44, 'Nora Roberts': 38, 'E L James': 33, 'Colleen Hoover': 33, 'Paula Hawkins': 30, 'David Baldacci': 18, 'Kathryn Stockett': 16, 'Michael Connelly': 15, 'Nicholas Sparks': 15, 'John Sandford': 15, 'Stephen King': 14, 'James Patterson and Maxine Paetro': 14, 'Janet Evanovich': 13, 'Dan Brown': 12, 'Kristin Hannah': 11, 'Lee Child': 10, 'Harlan Coben': 9, 'James Patterson': 9, 'Rebecca Yarros': 9, 'Sara Gruen': 8, 'Louise Penny': 8, 'James Patterson and Bill Clinton': 8, 'James Patterson and Michael Ledwidge': 7, 'Gillian Flynn': 7, 'Robert Galbraith': 7, 'Jojo Moyes': 7, 'Daniel Silva': 7, 'Elin Hilderbrand': 7, 'Danielle Steel': 6, 'Sylvia Day': 5, 'Diana Gabaldon': 5, 'Emily Henry': 5, 'Jodi Picoult': 4, 'James Patterson and Mark Sullivan': 4, 'Ken Follett': 4, 'Brad Thor': 4, 'Donna Tartt': 4, 'James Patterson and David Ellis': 4, 'Liane Moriarty': 4, 'Harper Lee': 4, 'Sandra Brown': 4, 'William P Young': 4, 'Ernest Cline': 4, 'Julia Quinn': 4, 'Amanda Gorman': 4, 'J R Ward': 3, 'Sue Grafton': 3, 'Patricia Briggs': 3, 'Anthony Doerr': 3, 'Andy Weir': 3, 'Douglas Preston and Lincoln Child': 3, 'Kevin Kwan': 3, 'Jeanine Cummins': 3, 'Sarah J. Maas': 3, 'Celeste Ng': 3, 'Brit Bennett': 3, 'Lee Child and Andrew Child': 3, 'Laura Dave': 3, 'Lisa Gardner': 2, 'Charlaine Harris': 2, 'Patricia Cornwell': 2, 'Stieg Larsson': 2, 'Jonathan Safran Foer': 2, 'Vince Flynn': 2, 'Ron Carr': 2, 'Brandon Sanderson': 2, 'Stuart Woods': 2, 'Nelson DeMille': 2, 'Catherine Coulter': 2, 'W Bruce Cameron': 2, 'A.J. Finn': 2, 'Kyle Mills': 2, 'James Patterson and James O. Born': 2, 'James Patterson and Brendan DuBois': 2, 'Jack Carr': 2, 'Ann Patchett': 2, 'Jean M Auel': 1, 'George R R Martin': 1, 'J K Rowling': 1, 'Tom Clancy with Mark Greaney': 1, 'Robert Jordan and Brandon Sanderson': 1, 'S C Stephens': 1, 'Jamie McGuire': 1, 'Rachel Van Dyken': 1, 'James Patterson and Howard Roughan': 1, 'Maya Banks': 1, 'Elizabeth George': 1, 'Sue Monk Kidd': 1, 'Emily Giffin': 1, 'Jim Butcher': 1, 'Deborah Harkness': 1, 'David Lagercrantz': 1, 'Vince Flynn and Kyle Mills': 1, 'James Patterson and Marshall Karp': 1, 'Pierce Brown': 1, 'Jeffrey Archer': 1, 'Clive Cussler and Justin Scott': 1, 'James Patterson and Candice Fox': 1, 'Jonathan Kellerman': 1, 'Greg Iles': 1, 'James Patterson with Maxine Paetro': 1, 'Debbie Macomber': 1, 'Stephen King and Owen King': 1, 'EL James': 1, 'Christine Feehan': 1, 'Clive Cussler and Graham Brown': 1, 'CJ Box': 1, 'JR Ward': 1, 'James Patterson and Nancy Allen': 1, 'George R.R. Martin': 1, 'Ta-Nehisi Coates': 1, 'Mark Greaney': 1, 'Hilary Mantel': 1, 'Sister Souljah': 1, 'Stacey Abrams': 1, 'E.L. James': 1, 'Quentin Tarantino': 1, 'Miranda Cowley Heller': 1, 'Amor Towles': 1, 'Hillary Rodham Clinton and Louise Penny': 1, 'Lucy Foley': 1, 'Tessa Bailey': 1, 'Dolly Parton and James Patterson': 1, 'Lucy Score': 1, 'C.J. Box': 1, 'Taylor Jenkins Reid': 1, 'Richard Osman': 1})\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "all_responses_month = {}\n",
    "\n",
    "input_filename = 'all_weeks.json'\n",
    "output_filename = 'all_months.json'\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "    all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "    title_counts = Counter(book['title'] for book in all_books)\n",
    "    author_counts = Counter(book['author'] for book in all_books)\n",
    "    \n",
    "    print(author_counts)\n",
    "\n",
    "#     for month in data.keys():\n",
    "#         book_list = data[month]\n",
    "#         book_list.reverse() # use highest week count\n",
    "        \n",
    "#         most_common_book = max(book_list, key=lambda book: title_counts[book['title']])\n",
    "#         if title_counts[most_common_book['title']] == 1: ## if same, use author count\n",
    "#             max_weeks_on_list = max(book_list, key=lambda book: book['weeks_on_list'])['weeks_on_list']\n",
    "#             most_common_books = [book for book in book_list if book['weeks_on_list'] == max_weeks_on_list]\n",
    "\n",
    "#             if len(most_common_books) == 1:\n",
    "#                 most_common_book = most_common_books[0]\n",
    "#             else:\n",
    "#                 most_common_book = max(book_list, key=lambda book: author_counts[book['author']])\n",
    "#             all_responses_month[month] = most_common_book\n",
    "#         print(most_common_book['title'])\n",
    "\n",
    "#         all_responses_month[month] = most_common_book\n",
    "\n",
    "# with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "#     json.dump(all_responses_month, json_output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTHOR INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "all_responses_month = {}\n",
    "\n",
    "author_input_filename = 'author_info.json'\n",
    "input_filename = 'all_months.json'\n",
    "output_filename = 'all_months_author.json'\n",
    "\n",
    "with open(author_input_filename, 'r', encoding='utf-8') as author_read_file:\n",
    "    author_data = json.load(author_read_file)\n",
    "\n",
    "    with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "        data = json.load(read_file)\n",
    "\n",
    "        for month in data.keys():\n",
    "            book = data[month]\n",
    "            author_names = book['author'].split(' and ')\n",
    "            book['author'] = author_names\n",
    "\n",
    "            author_info = {}\n",
    "\n",
    "            for author in author_names:\n",
    "                author_info[author] = {}\n",
    "\n",
    "                for key in author_data['James Patterson']:\n",
    "                    if key=='books':\n",
    "                        continue\n",
    "                    if not author in author_data:\n",
    "                        print(book['author'])\n",
    "                    author_info[author][key] = author_data[author][key]\n",
    "\n",
    "            book['author'] = author_info\n",
    "\n",
    "            all_responses_month[month] = book\n",
    "\n",
    "\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(all_responses_month, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to author_info.json\n"
     ]
    }
   ],
   "source": [
    "## add all books from all_weeks to author_info\n",
    "# import json\n",
    "\n",
    "# existing_json_filename = 'save-author_info.json'\n",
    "# new_json_filename = 'all_weeks.json'\n",
    "# output_filename = 'author_info.json'\n",
    "\n",
    "# # Load the existing JSON data\n",
    "# with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "#     existing_data = json.load(existing_file)\n",
    "\n",
    "# # Load the new JSON data\n",
    "# with open(new_json_filename, 'r', encoding='utf-8') as new_file:\n",
    "#     new_data = json.load(new_file)\n",
    "\n",
    "# # Update the existing JSON data with additional book information\n",
    "# for month, books in new_data.items():\n",
    "#     for book_entry in books:\n",
    "#         author_names = book_entry['author'].split(' and ')\n",
    "#         for author_name in author_names:\n",
    "#             # Check if the author exists in the existing data\n",
    "#             if author_name in existing_data:\n",
    "#                 book_title = book_entry['title']\n",
    "#                 # Add the book to the author's list of books if it's not already present\n",
    "#                 if book_title not in existing_data[author_name]['books']:\n",
    "#                     existing_data[author_name]['books'].append(book_title)\n",
    "\n",
    "# # Save the updated data to a new JSON file\n",
    "# with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "#     json.dump(existing_data, output_file, indent=2)\n",
    "\n",
    "# print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to author_info.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "existing_json_filename = 'save-author_info.json'\n",
    "output_filename = 'author_info.json'\n",
    "\n",
    "# Load the existing JSON data\n",
    "with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "    existing_data = json.load(existing_file)\n",
    "\n",
    "# Prompt the user to input the date of birth for each author\n",
    "for author_name, author_info in existing_data.items():\n",
    "    # BIRTHHHH\n",
    "    # if 'birth_year' not in author_info:\n",
    "    #     # Prompt the user for input\n",
    "    #     date_of_birth = input(f\"Enter the year of birth for {author_name}: \")\n",
    "        \n",
    "    #     # Update the existing data with the date of birth\n",
    "    #     existing_data[author_name]['birth_year'] = date_of_birth\n",
    "\n",
    "    # BOOK COUNT\n",
    "    existing_data[author_name]['multiple_books'] = len(existing_data[author_name]['books']) > 1\n",
    "\n",
    "# Save the updated data to a new JSON file\n",
    "with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(existing_data, output_file, indent=2)\n",
    "\n",
    "print(f\"Updated data saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to all_months.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "json_filename = 'all_months_author.json'\n",
    "csv_filename = 'all_months.csv'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_filename, 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_filename, 'w', encoding='utf-8', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the header to the CSV file\n",
    "    header = list(data['2011-02'].keys())\n",
    "    header.remove('author')\n",
    "    author_header = list(data['2011-02']['author']['James Patterson'].keys())\n",
    "    csv_writer.writerow(header+['author']+author_header)\n",
    "    \n",
    "    # Iterate through each month in the JSON data\n",
    "    for month, book_data in data.items():\n",
    "        for author, author_data in book_data['author'].items():\n",
    "            book_data['date'] = month\n",
    "            data = [book_data[key] for key in header] + [author] + [author_data[key] for key in author_header]\n",
    "\n",
    "            csv_writer.writerow(data)\n",
    "\n",
    "print(f\"CSV file saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGAIN FOR AUTHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "all_responses_author = {}\n",
    "\n",
    "input_filename = 'all_weeks.json'\n",
    "output_filename = 'all_authors.json'\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "    all_books = [book for month_data in data.values() for book in month_data]\n",
    "\n",
    "    title_counts = Counter(book['title'] for book in all_books)\n",
    "    author_counts = Counter(author.strip() for book in all_books for author in book['author'].split(' and '))\n",
    "\n",
    "    popular_authors = {author:count for author, count in author_counts.items() if count > 5}\n",
    "    \n",
    "    print(len(popular_authors))\n",
    "\n",
    "    for month, books in data.items():\n",
    "        for book_entry in books:\n",
    "            author_names = book_entry['author'].split(' and ')\n",
    "            for author_name in author_names:\n",
    "                # Check if the author exists in the existing data\n",
    "                if author_name in popular_authors:\n",
    "                    if author_name not in all_responses_author:\n",
    "                        all_responses_author[author_name] = {}\n",
    "                        all_responses_author[author_name]['books']=[]\n",
    "\n",
    "                    if any(entry['title'] == book_entry['title'] for entry in all_responses_author[author_name]['books']):\n",
    "                        for entry in all_responses_author[author_name]['books']:\n",
    "                            if entry['title'] == book_entry['title']:\n",
    "                                entry['book_count'] += 1\n",
    "                                entry['dates'].append(book_entry['date'])\n",
    "                                entry['weeks_on_list'] = book_entry['weeks_on_list']\n",
    "                    else: \n",
    "                        copied = copy.deepcopy(book_entry)\n",
    "                        copied['book_count'] = 1\n",
    "                        copied['dates'] = [book_entry['date']]\n",
    "                        del copied['date']\n",
    "                        del copied['rank']\n",
    "                        del copied['dagger']\n",
    "            \n",
    "                        all_responses_author[author_name]['count'] = popular_authors[author_name]\n",
    "                        all_responses_author[author_name]['books'].append(copied)\n",
    "                    \n",
    "all_responses_author = dict(sorted(all_responses_author.items(),key=lambda x: x[1]['count'], reverse=True))\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as json_output_file:\n",
    "    json.dump(all_responses_author, json_output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan College\n",
      "Mississippi State University\n",
      "University of Georgia\n",
      "\n",
      "University of Kent\n",
      "Texas A&M University-Commerce\n",
      "Politics, Philosophy, and Economics\n",
      "Virginia Commonwealth University\n",
      "English\n",
      "Journalism\n",
      "University of Notre Dame\n",
      "English\n",
      "University of Iowa\n",
      "Jacksonville University\n",
      "Rutgers University\n",
      "University of Sheffield\n",
      "Amherst College\n",
      "University of Washington\n",
      "Amherst College\n",
      "Toronto Metropolitan University\n",
      "University of Colorado\n",
      "Carleton University\n",
      "Georgetown University\n",
      "Manhattan College\n",
      "University of Kansas\n",
      "University of Exeter\n",
      "University of London\n",
      "California State University Fresno\n",
      "Johns Hopkins University\n",
      "Parsons School of Design\n"
     ]
    }
   ],
   "source": [
    "input_filename = 'all_authors.json'\n",
    "existing_json_filename = 'author_info.json'\n",
    "output_filename = 'all_authors_update.json'\n",
    "\n",
    "with open(input_filename, 'r', encoding='utf-8') as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "with open(existing_json_filename, 'r', encoding='utf-8') as existing_file:\n",
    "    existing_data = json.load(existing_file)\n",
    "\n",
    "# Prompt the user to input the date of birth for each author\n",
    "for author_name, author_info in existing_data.items():\n",
    "    if author_name in data:\n",
    "        data[author_name]['gender'] = author_info['gender']\n",
    "        data[author_name]['birth_year'] = int(author_info['birth_year'])\n",
    "        data[author_name]['university'] = author_info['university']\n",
    "        data[author_name]['major'] = author_info['major']\n",
    "\n",
    "for author_name, author_info in data.items():\n",
    "    if 'gender' not in author_info:\n",
    "        gender = input(f\"input {author_name}'s gender\")\n",
    "        data[author_name]['gender'] = gender\n",
    "    if 'birth_year' not in author_info:\n",
    "        birth_year = input(f\"input {author_name}'s birth year\")\n",
    "        data[author_name]['birth_year'] = birth_year\n",
    "    if 'university' not in author_info:\n",
    "        university = input(f\"input {author_name}'s university\")\n",
    "        data[author_name]['university'] = university\n",
    "    if 'major' not in author_info:\n",
    "        major = input(f\"input {author_name}'s major\")\n",
    "        data[author_name]['major'] = major\n",
    "    \n",
    "    print(data[author_name]['university'])\n",
    "    university = input(f\"type something to change {author_name}'s university\")\n",
    "    if university:\n",
    "        print(\"HI\")\n",
    "        data[author_name]['university'] = university\n",
    "\n",
    "\n",
    "# Save the updated data to a new JSON file\n",
    "with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(data, output_file, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
